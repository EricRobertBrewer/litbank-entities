{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e01e402-3697-4434-8b07-03e979eec055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brewer/Code/UU/CS6390/litbank-entities\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1443baf-4958-4e74-bf60-10a8b730dc75",
   "metadata": {},
   "source": [
    "# demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c95e18b-17e5-43e8-83b0-4752d26ed152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 10:10:09.976835: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from litbank_entities import extract, linguistics, litbank\n",
    "from litbank_entities.model import hmm_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720f87f6-052d-4cf1-8dd4-a7d664883aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = 'models'\n",
    "MODEL_NAME = 'demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a9add-669b-4035-b6c1-36bc16c8f19e",
   "metadata": {},
   "source": [
    "## Load data, language utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9443c036-2025-4cfc-887d-0d7a6e648598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sentences: 8567\n"
     ]
    }
   ],
   "source": [
    "text_sentence_tokens, text_sentence_labels = litbank.get_text_sentence_tokens_labels()\n",
    "sentence_tokens, sentence_labels = litbank.flatten_texts(text_sentence_tokens, text_sentence_labels)\n",
    "sentence_tokens, sentence_labels = linguistics.process(sentence_tokens, sentence_labels)\n",
    "sentence_tokens, sentence_labels = litbank.split_large_sentences(sentence_tokens, sentence_labels)\n",
    "assert len(sentence_tokens) == len(sentence_labels)\n",
    "print('Train sentences: {:d}'.format(len(sentence_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ddca3c1-c156-45e1-b29d-4755e732c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = linguistics.get_nlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de3c2f-0ad6-4528-8bb3-f2b804642bce",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835896a4-d1f2-43e1-be99-f00be1adae0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8232c78ffa4927a1f720a4e1d20f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', options=('CRF (Conditional Random Field)', 'HMM (Hidden Markov Model using only…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_options = [\n",
    "    'CRF (Conditional Random Field)',\n",
    "    'HMM (Hidden Markov Model using only tokens)',\n",
    "    'ZeroR (dummy baseline)'\n",
    "]\n",
    "model_names = ['crf', 'hmm', 'zero']\n",
    "model_option_to_name = {model_options[i]: model_names[i] for i in range(len(model_options))}\n",
    "\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=model_options,\n",
    "    value=model_options[0],\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "034a710d-d44c-4f87-9fee-100d4261bdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 10:11:02.461145: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "classname = model_option_to_name[model_dropdown.value]\n",
    "categories = litbank.ENTITY_CATEGORIES\n",
    "resources = extract.create_model_resources(classname)\n",
    "model = extract.create_model(classname, categories, resources)\n",
    "\n",
    "model_dir = os.path.join(MODELS_DIR, classname)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "demo_dir = os.path.join(model_dir, MODEL_NAME)\n",
    "if not os.path.exists(demo_dir) or \\\n",
    "        any(not os.path.exists(os.path.join(demo_dir, 'model_{}'.format(category))) for category in categories):\n",
    "    print('Training model...')\n",
    "    model.train(sentence_tokens, sentence_labels)\n",
    "    print('Done.')\n",
    "    model.save_model(demo_dir)\n",
    "    print('Saved model.')\n",
    "else:\n",
    "    print('Loaded model.')\n",
    "    model.load_model(demo_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055881a3-a566-4542-b391-bb435e281088",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f08c28e-1e82-4700-a706-122ee6cb2fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec184f0418e48a59418d799e5f4f3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='We have witnessed this morning the distant view a brief full battle of Pearl Harbor and the se…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pearl_harbor = \\\n",
    "    'We have witnessed this morning the distant view a brief full battle of Pearl Harbor' \\\n",
    "    ' and the severe bombing of Pearl Harbor by enemy planes, undoubtedly Japanese.\\n' \\\n",
    "    'The city of Honolulu has also been attacked and considerable damage done.'\n",
    "sentence_textarea = widgets.Textarea(\n",
    "    value=pearl_harbor,\n",
    "    placeholder='Sentences separated by newline characters.',\n",
    "    description='Find entities:',\n",
    "    layout={'height': '16em'},\n",
    ")\n",
    "display(sentence_textarea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99d83899-07a7-423c-bc80-749372cc3d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brewer/Code/UU/CS6390/litbank-entities/venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff1a079df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff1a119c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "                   PER   FAC   GPE   LOC   VEH   ORG  \n",
      "                We O     O     O     O     O     O    \n",
      "              have O     O     O     O     O     O    \n",
      "         witnessed O     O     O     O     O     O    \n",
      "              this O     O     O     O     O     O    \n",
      "           morning O     O     O     O     O     O    \n",
      "               the O     O     O     O     O     O    \n",
      "           distant O     O     O     O     O     O    \n",
      "              view O     O     O     O     O     O    \n",
      "                 a O     O     O     O     O     O    \n",
      "             brief O     O     O     I-LOC O     O    \n",
      "              full O     O     O     I-LOC O     O    \n",
      "            battle O     O     O     I-LOC O     O    \n",
      "                of O     O     O     I-LOC O     O    \n",
      "             Pearl B-PER O     B-GPE I-LOC O     O    \n",
      "            Harbor I-PER O     O     I-LOC O     O    \n",
      "               and O     O     O     O     O     O    \n",
      "               the O     O     O     B-LOC O     O    \n",
      "            severe O     O     O     I-LOC O     O    \n",
      "           bombing O     O     O     I-LOC O     O    \n",
      "                of O     O     O     I-LOC O     O    \n",
      "             Pearl B-PER O     O     I-LOC O     O    \n",
      "            Harbor I-PER O     O     I-LOC O     O    \n",
      "                by O     O     O     O     O     O    \n",
      "             enemy O     O     O     O     O     O    \n",
      "           planes, O     O     O     O     O     O    \n",
      "       undoubtedly O     O     O     O     O     O    \n",
      "         Japanese. O     O     O     O     O     O    \n",
      "               The O     O     O     O     O     O    \n",
      "              city O     O     O     O     O     O    \n",
      "                of O     O     O     O     O     O    \n",
      "          Honolulu O     O     O     O     O     O    \n",
      "               has O     O     O     O     O     O    \n",
      "              also O     O     O     O     O     O    \n",
      "              been O     O     O     O     O     O    \n",
      "          attacked O     O     O     O     O     O    \n",
      "               and O     O     O     O     O     O    \n",
      "      considerable O     O     O     O     O     O    \n",
      "            damage O     O     O     O     O     O    \n",
      "             done. O     O     O     O     O     O    \n"
     ]
    }
   ],
   "source": [
    "test_sentence_tokens = [list(map(str, nlp(sentence))) for sentence in sentence_textarea.value.split('\\n')]\n",
    "test_sentence_preds = model.predict(test_sentence_tokens)\n",
    "\n",
    "token_spaces = 18\n",
    "print(' ' * token_spaces, end='')\n",
    "for category in categories:\n",
    "    print(' {:<5}'.format(category), end='')\n",
    "print()\n",
    "for s, tokens in enumerate(test_sentence_tokens):\n",
    "    preds = test_sentence_preds[s]\n",
    "    for i, token in enumerate(tokens):\n",
    "        print('{:>{w}}'.format(token, w=token_spaces), end='')\n",
    "        for nest_pred in preds[i]:\n",
    "            print(' {:<5}'.format(nest_pred), end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1bb841-7fc0-4c85-8fdd-e0708866bce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litbank-entities",
   "language": "python",
   "name": "litbank-entities"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
